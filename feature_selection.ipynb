{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Shape : (137166, 23)\n",
      "Index(['Unnamed: 0', 'Zip Code', 'Month of Period End', 'Median Sale Price',\n",
      "       'Median Sale Price MoM ', 'Median Sale Price YoY ', 'Homes Sold',\n",
      "       'Homes Sold MoM ', 'Homes Sold YoY ', 'New Listings',\n",
      "       'New Listings MoM ', 'New Listings YoY ', 'Inventory', 'Inventory MoM ',\n",
      "       ' Inventory YoY ', 'Days on Market', 'Days on Market MoM',\n",
      "       'Days on Market YoY', 'Average Sale To List',\n",
      "       'Average Sale To List MoM ', 'Average Sale To List YoY ',\n",
      "       'record_month', 'PSSF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#load dataframe from csv\n",
    "merged_sales = pd.read_csv(\"data/zip/merged_sales_stats.csv\", delimiter='\t')\n",
    "\n",
    "#print dataframe shape\n",
    "shape = merged_sales.shape\n",
    "print('\\nDataFrame Shape :', shape)\n",
    "\n",
    "print(merged_sales.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged_sales_statistics file has all the statistics as columns and zip codes and dates as the rows. I tried to transpose these but it got weird. So let's get some stuff from the merged_sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1688, 682)\n",
      "Index(['Unnamed: 0', 'Zip Code', 'June 2009 1bd', 'July 2009 1bd',\n",
      "       'August 2009 1bd', 'September 2009 1bd', 'October 2009 1bd',\n",
      "       'November 2009 1bd', 'December 2009 1bd', 'January 2010 1bd',\n",
      "       ...\n",
      "       'December 2019 5bd', 'January 2020 5bd', 'February 2020 5bd',\n",
      "       'March 2020 5bd', 'April 2020 5bd', 'May 2020 5bd', 'June 2020 5bd',\n",
      "       'July 2020 5bd', 'August 2020 5bd', 'September 2020 5bd'],\n",
      "      dtype='object', length=682)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load dataframe from csv\n",
    "merged_bedroom_data = pd.read_csv(\"data/zip/merged_bedrooms.csv\", delimiter='\t')\n",
    "print(merged_bedroom_data.shape)\n",
    "print(merged_bedroom_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 207)\n",
      "0     29.100000\n",
      "1     31.900000\n",
      "2     30.700001\n",
      "3     37.599998\n",
      "4     33.000000\n",
      "5     36.099998\n",
      "6     30.799999\n",
      "7     33.700001\n",
      "8     29.500000\n",
      "9     29.100000\n",
      "10    33.299999\n",
      "11    30.299999\n",
      "12    32.099998\n",
      "13    31.799999\n",
      "14    27.299999\n",
      "15    32.799999\n",
      "16    29.900000\n",
      "17    42.599998\n",
      "18    32.099998\n",
      "19    30.799999\n",
      "20    33.200001\n",
      "21    32.400002\n",
      "22    33.000000\n",
      "23    32.700001\n",
      "24    22.299999\n",
      "25    31.500000\n",
      "26    33.099998\n",
      "27    27.600000\n",
      "28    33.000000\n",
      "29    27.600000\n",
      "30    32.200001\n",
      "31    27.200001\n",
      "32    30.600000\n",
      "33    31.500000\n",
      "34    31.700001\n",
      "35    33.500000\n",
      "36    26.700001\n",
      "37    29.400000\n",
      "38    33.200001\n",
      "39    31.000000\n",
      "40    30.600000\n",
      "Name: SE_A18003_001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "now for our demographic info, it's from 2019 so not super up to date, but pretty close and there's a lot of it\n",
    "'''\n",
    "demographics = pd.read_csv(\"data/zip/ca_demographics.csv\", delimiter='\t')\n",
    "zip_to_county = pd.read_csv(\"data/zip/zip_to_county.csv\", delimiter='\t')\n",
    "\n",
    "print(demographics.shape) # a lot of blank columns\n",
    "\n",
    "\n",
    "print(demographics[\"SE_A18003_001\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the column names are gibberish, so we'll need to use the [ca_demographics_key.txt](data/zip/ca_demographics_key.txt) to make sense of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1763, 217)\n"
     ]
    }
   ],
   "source": [
    "zipdemo = pd.read_csv(\"data/zip/ca_zip_demograhics.csv\", delimiter='\t')\n",
    "print(zipdemo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot to look at in that dataset, but certainly all the key indicators about the zip should give us at least some picture of what the housing market there might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Condensing Sale Data to Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove month from \"Month of Period End\"\n",
    "only_year_query = \"\"\"SELECT \"Zip Code\" as zip_code, \n",
    "                    SUBSTR(\"Month of Period End\" ,-4) as year,\n",
    "                    \"Median Sale Price\" as med_sale_price,\n",
    "                    \"Homes Sold\" as home_sold,\n",
    "                    \"New Listings\" as new_listings,\n",
    "                    \"Inventory\" as inventory,\n",
    "                    \"Days on Market\" as days_on_market,\n",
    "                    \"Average Sale To List\" as avg_sale_to_list,\n",
    "                    PSSF as ppsf\n",
    "                    FROM merged_sales\"\"\"\n",
    "only_year = ps.sqldf(only_year_query, locals())\n",
    "\n",
    "#group by year\n",
    "cond_year_query = \"\"\"SELECT zip_code, \n",
    "                            year,\n",
    "                            AVG(med_sale_price) as med_sale_price,\n",
    "                            SUM(home_sold) as homes_sold,\n",
    "                            SUM(new_listings) as new_listings,\n",
    "                            AVG(inventory) as inventory,\n",
    "                            AVG(days_on_market) as days_on_market,\n",
    "                            AVG(avg_sale_to_list) as avg_sale_to_list,\n",
    "                            AVG(ppsf) as ppsf\n",
    "                    FROM only_year\n",
    "                    GROUP BY year, zip_code\"\"\"\n",
    "cond_year = ps.sqldf(cond_year_query, locals())\n",
    "\n",
    "#filtering to 2018\n",
    "year_18_query = \"\"\"SELECT *\n",
    "                    FROM cond_year\n",
    "                    WHERE year = '2018' \"\"\"\n",
    "year_18 = ps.sqldf(year_18_query, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 Sales and Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>year</th>\n",
       "      <th>med_sale_price</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>avg_sale_to_list</th>\n",
       "      <th>ppsf</th>\n",
       "      <th>Geo_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>SE_A08002B_005</th>\n",
       "      <th>SE_A08002B_006</th>\n",
       "      <th>SE_A10066_001</th>\n",
       "      <th>SE_A10066_002</th>\n",
       "      <th>SE_A10066_003</th>\n",
       "      <th>SE_A10066_004</th>\n",
       "      <th>SE_A10066_005</th>\n",
       "      <th>SE_A10066_006</th>\n",
       "      <th>SE_A10066_007</th>\n",
       "      <th>SE_A10066_008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90001</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.228333e+05</td>\n",
       "      <td>511</td>\n",
       "      <td>678.0</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>100.125000</td>\n",
       "      <td>322.500000</td>\n",
       "      <td>90090001</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>118</td>\n",
       "      <td>13815</td>\n",
       "      <td>1834</td>\n",
       "      <td>2083</td>\n",
       "      <td>2594</td>\n",
       "      <td>2513</td>\n",
       "      <td>2045</td>\n",
       "      <td>1330</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90002</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.825000e+05</td>\n",
       "      <td>964</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>39.916667</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>323.750000</td>\n",
       "      <td>90090002</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>124</td>\n",
       "      <td>12706</td>\n",
       "      <td>2096</td>\n",
       "      <td>2232</td>\n",
       "      <td>2020</td>\n",
       "      <td>2266</td>\n",
       "      <td>1719</td>\n",
       "      <td>895</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90003</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.076667e+05</td>\n",
       "      <td>962</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>45.416667</td>\n",
       "      <td>99.933333</td>\n",
       "      <td>314.166667</td>\n",
       "      <td>90090003</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>129</td>\n",
       "      <td>17127</td>\n",
       "      <td>2594</td>\n",
       "      <td>2479</td>\n",
       "      <td>2966</td>\n",
       "      <td>3345</td>\n",
       "      <td>2757</td>\n",
       "      <td>1476</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90004</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.286500e+06</td>\n",
       "      <td>747</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>99.233333</td>\n",
       "      <td>630.916667</td>\n",
       "      <td>90090004</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>463</td>\n",
       "      <td>21971</td>\n",
       "      <td>6379</td>\n",
       "      <td>6385</td>\n",
       "      <td>3842</td>\n",
       "      <td>2854</td>\n",
       "      <td>1539</td>\n",
       "      <td>721</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90005</td>\n",
       "      <td>2018</td>\n",
       "      <td>7.710000e+05</td>\n",
       "      <td>314</td>\n",
       "      <td>446.0</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>99.225000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>90090005</td>\n",
       "      <td>...</td>\n",
       "      <td>431</td>\n",
       "      <td>380</td>\n",
       "      <td>16442</td>\n",
       "      <td>6298</td>\n",
       "      <td>4939</td>\n",
       "      <td>2183</td>\n",
       "      <td>1794</td>\n",
       "      <td>832</td>\n",
       "      <td>293</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>96146</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.807500e+05</td>\n",
       "      <td>249</td>\n",
       "      <td>368.0</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>163.333333</td>\n",
       "      <td>95.691667</td>\n",
       "      <td>486.333333</td>\n",
       "      <td>96196146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>454</td>\n",
       "      <td>152</td>\n",
       "      <td>215</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>96148</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.440833e+05</td>\n",
       "      <td>155</td>\n",
       "      <td>156.0</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>96.950000</td>\n",
       "      <td>413.666667</td>\n",
       "      <td>96196148</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>96150</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.536667e+05</td>\n",
       "      <td>2333</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>246.333333</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>97.008333</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>96196150</td>\n",
       "      <td>...</td>\n",
       "      <td>461</td>\n",
       "      <td>24</td>\n",
       "      <td>11536</td>\n",
       "      <td>3645</td>\n",
       "      <td>4315</td>\n",
       "      <td>1666</td>\n",
       "      <td>1221</td>\n",
       "      <td>427</td>\n",
       "      <td>202</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>96155</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.340000e+05</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>145.666667</td>\n",
       "      <td>96196155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>96161</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.946667e+05</td>\n",
       "      <td>2534</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>289.500000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>97.816667</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>96196161</td>\n",
       "      <td>...</td>\n",
       "      <td>233</td>\n",
       "      <td>59</td>\n",
       "      <td>6929</td>\n",
       "      <td>1385</td>\n",
       "      <td>2772</td>\n",
       "      <td>1087</td>\n",
       "      <td>1437</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1337 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_code  year  med_sale_price  homes_sold  new_listings   inventory  \\\n",
       "0        90001  2018    4.228333e+05         511         678.0   44.333333   \n",
       "1        90002  2018    3.825000e+05         964        1178.0   74.666667   \n",
       "2        90003  2018    4.076667e+05         962        1222.0   96.000000   \n",
       "3        90004  2018    1.286500e+06         747        1117.0   85.833333   \n",
       "4        90005  2018    7.710000e+05         314         446.0   30.666667   \n",
       "...        ...   ...             ...         ...           ...         ...   \n",
       "1332     96146  2018    5.807500e+05         249         368.0   62.666667   \n",
       "1333     96148  2018    6.440833e+05         155         156.0   14.583333   \n",
       "1334     96150  2018    4.536667e+05        2333        3039.0  246.333333   \n",
       "1335     96155  2018    2.340000e+05           8           NaN         NaN   \n",
       "1336     96161  2018    6.946667e+05        2534        3015.0  289.500000   \n",
       "\n",
       "      days_on_market  avg_sale_to_list        ppsf  Geo_FIPS  ...  \\\n",
       "0          43.166667        100.125000  322.500000  90090001  ...   \n",
       "1          39.916667         99.916667  323.750000  90090002  ...   \n",
       "2          45.416667         99.933333  314.166667  90090003  ...   \n",
       "3          33.833333         99.233333  630.916667  90090004  ...   \n",
       "4          30.250000         99.225000  523.000000  90090005  ...   \n",
       "...              ...               ...         ...       ...  ...   \n",
       "1332      163.333333         95.691667  486.333333  96196146  ...   \n",
       "1333       90.500000         96.950000  413.666667  96196148  ...   \n",
       "1334       43.750000         97.008333  307.666667  96196150  ...   \n",
       "1335      104.000000         91.333333  145.666667  96196155  ...   \n",
       "1336       65.250000         97.816667  367.000000  96196161  ...   \n",
       "\n",
       "     SE_A08002B_005 SE_A08002B_006 SE_A10066_001 SE_A10066_002  SE_A10066_003  \\\n",
       "0               144            118         13815          1834           2083   \n",
       "1                45            124         12706          2096           2232   \n",
       "2               193            129         17127          2594           2479   \n",
       "3               483            463         21971          6379           6385   \n",
       "4               431            380         16442          6298           4939   \n",
       "...             ...            ...           ...           ...            ...   \n",
       "1332              0              9           454           152            215   \n",
       "1333             24              0           210            55             62   \n",
       "1334            461             24         11536          3645           4315   \n",
       "1335              0              0             0             0              0   \n",
       "1336            233             59          6929          1385           2772   \n",
       "\n",
       "      SE_A10066_004 SE_A10066_005  SE_A10066_006 SE_A10066_007 SE_A10066_008  \n",
       "0              2594          2513           2045          1330          1416  \n",
       "1              2020          2266           1719           895          1478  \n",
       "2              2966          3345           2757          1476          1510  \n",
       "3              3842          2854           1539           721           251  \n",
       "4              2183          1794            832           293           103  \n",
       "...             ...           ...            ...           ...           ...  \n",
       "1332             31            24             32             0             0  \n",
       "1333              6            50             26             0            11  \n",
       "1334           1666          1221            427           202            60  \n",
       "1335              0             0              0             0             0  \n",
       "1336           1087          1437            187             0            61  \n",
       "\n",
       "[1337 rows x 226 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip code = Geo_ZCTA5\n",
    "\n",
    "sales_demo_query = \"\"\"SELECT year_18.*, zipdemo.*\n",
    "                    FROM year_18\n",
    "                    INNER JOIN zipdemo on zip_code = Geo_ZCTA5\n",
    "                    \"\"\"\n",
    "sales_demo = ps.sqldf(sales_demo_query, locals())\n",
    "sales_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DoM_group</th>\n",
       "      <th>COUNT(zip_code)</th>\n",
       "      <th>MAX(days_on_market)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>21.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>34.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>267</td>\n",
       "      <td>44.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>59.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>267</td>\n",
       "      <td>2833.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DoM_group  COUNT(zip_code)  MAX(days_on_market)\n",
       "0          1              268            21.416667\n",
       "1          2              268            34.750000\n",
       "2          3              267            44.083333\n",
       "3          4              267            59.416667\n",
       "4          5              267          2833.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create avg_sale_to_list groups (split into 5)\n",
    "ntile_DoM_query = \"\"\"SELECT *, NTILE(5) OVER (\n",
    "                            ORDER BY days_on_market ASC) as DoM_group      \n",
    "                        FROM sales_demo\"\"\"\n",
    "ntile_DoM = ps.sqldf(ntile_DoM_query, locals())\n",
    "\n",
    "\n",
    "#see group maximums\n",
    "minmax_DoM_query = \"\"\"SELECT DoM_group, COUNT(zip_code), MAX(days_on_market)\n",
    "                        FROM ntile_DoM\n",
    "                        GROUP BY DoM_group\"\"\"\n",
    "minmax_DoM = ps.sqldf(minmax_DoM_query, locals())\n",
    "minmax_DoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete non-numeric and unused columns.\n",
    "del_col = ['Geo_FIPS', 'Geo_GEOID', 'Geo_NAME', 'Geo_QName', 'Geo_STUSAB', 'Geo_SUMLEV', \n",
    "           'Geo_GEOCOMP', 'Geo_FILEID', 'Geo_LOGRECNO', 'Geo_US', 'Geo_REGION', 'Geo_DIVISION', \n",
    "          'Geo_STATECE', 'Geo_STATE', 'Geo_COUNTY', 'Geo_COUSUB', 'Geo_PLACE', 'Geo_PLACESE', \n",
    "          'Geo_TRACT', 'Geo_BLKGRP', 'Geo_CONCIT', 'Geo_AIANHH', 'Geo_AIANHHFP', 'Geo_AIHHTLI', \n",
    "          'Geo_AITSCE', 'Geo_AITS', 'Geo_ANRC', 'Geo_CBSA', 'Geo_CSA', 'Geo_METDIV', 'Geo_MACC', \n",
    "          'Geo_MEMI', 'Geo_NECTA', 'Geo_CNECTA', 'Geo_NECTADIV', 'Geo_UA', 'Geo_UACP', 'Geo_CDCURR', \n",
    "          'Geo_SLDU', 'Geo_SLDL', 'Geo_VTD', 'Geo_ZCTA3', 'Geo_SUBMCD', 'Geo_SDELM', 'Geo_SDSEC', \n",
    "          'Geo_SDUNI', 'Geo_UR', 'Geo_PCI', 'Geo_TAZ', 'Geo_UGA', 'Geo_BTTR', 'Geo_BTBG', \n",
    "          'Geo_PUMA5', 'Geo_PUMA1', 'year','Geo_ZCTA5', 'avg_sale_to_list']\n",
    "for i in del_col:\n",
    "    del ntile_DoM[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables to hold test and training data.\n",
    "\n",
    "# Shuffle data frame.\n",
    "shuffled = ntile_DoM.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Remove blanks and NaNs\n",
    "shuffled.replace('', np.nan)\n",
    "shuffled = shuffled.dropna(axis=0, how='any')\n",
    "\n",
    "# Split into data and labels.\n",
    "labels = shuffled[\"DoM_group\"]\n",
    "del shuffled[\"DoM_group\"]\n",
    "zip_codes = shuffled[\"zip_code\"]\n",
    "del shuffled[\"zip_code\"]\n",
    "shuffled = shuffled.apply(lambda x: pd.to_numeric(x))\n",
    "\n",
    "# Create 80% split point.\n",
    "split = int(len(shuffled)*0.8//1)\n",
    "\n",
    "# Store in variables.\n",
    "train_data = shuffled[:split]\n",
    "train_labels = labels[:split]\n",
    "test_data = shuffled[split+1:]\n",
    "test_labels = labels[split+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3989909  0.15741318 0.10676879 0.05174286 0.0287918  0.02303178\n",
      " 0.01975653 0.01775321 0.01589618 0.01516186 0.01150166 0.00995284\n",
      " 0.00899551 0.00813939 0.00804748 0.00634838 0.00582772 0.00544345\n",
      " 0.00511428 0.0045773 ] 0.9092550972991045\n",
      "[152.0707484   95.51789237  78.66587009  54.76327265  40.85061381\n",
      "  36.53658618  33.8391535   32.07765968  30.35362679  29.64425213\n",
      "  25.81929685  24.01804962  22.83374097  21.72001257  21.59702877\n",
      "  19.18207737  18.37864384  17.76239377  17.21696429  16.28803467]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize all of our data if possible\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(train_data)\n",
    "X_test = sc.transform(test_data)\n",
    "\n",
    "#now perform PCA\n",
    "pca = PCA(n_components=20)\n",
    "#pca.fit(X_train)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_, np.sum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=12, random_state=0)\n",
    "classifier.fit(X_train, train_labels)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predicted_labels = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != predicted_labels)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(\"Accuracy of our PCA model w/Random Forest : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 1 1 4 2 1 1 1 2 3 4 3 3 3 4 4 4 1 1 1 1 2 1 4 5 4 4 1 4 4 1 4 3 4 2\n",
      " 4 5 1 5 5 3 3 1 1 3 4 1 2 2 4 4 1 1 3 5 2 1 5 2 3 2 1 4 5 2 5 1 3 1 3 3 5\n",
      " 3 3 2 1 1 1 3 3 3 2 3 3]\n",
      "0.9767441860465116\n",
      "Thresh=0.001, n=15, Accuracy: 97.67%\n",
      "Thresh=0.001, n=14, Accuracy: 97.67%\n",
      "Thresh=0.001, n=13, Accuracy: 97.67%\n",
      "Thresh=0.002, n=12, Accuracy: 97.67%\n",
      "Thresh=0.002, n=11, Accuracy: 97.67%\n",
      "Thresh=0.002, n=10, Accuracy: 97.67%\n",
      "Thresh=0.002, n=9, Accuracy: 97.67%\n",
      "Thresh=0.002, n=8, Accuracy: 97.67%\n",
      "Thresh=0.002, n=7, Accuracy: 97.67%\n",
      "Thresh=0.002, n=6, Accuracy: 97.67%\n",
      "Thresh=0.003, n=5, Accuracy: 97.67%\n",
      "Thresh=0.003, n=4, Accuracy: 97.67%\n",
      "Thresh=0.003, n=3, Accuracy: 97.67%\n",
      "Thresh=0.006, n=2, Accuracy: 97.67%\n",
      "Thresh=0.968, n=1, Accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_data, train_labels)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(test_data)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != y_pred)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "# accuracy = accuracy_score(test_data, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# Fit model using each importance as a threshold\n",
    "\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    if(thresh > 0.00001):\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(train_data)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier()\n",
    "        selection_model.fit(select_X_train, train_labels)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(test_data)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
